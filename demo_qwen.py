#!/usr/bin/env python3
"""
äº¤äº’å¼æ¼”ç¤ºç¨‹åºï¼Œæ”¯æŒå¤šè½®å¯¹è¯å’Œå·¥å…·è°ƒç”¨
"""

import json
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
import re
from fake_search import FakeSearch

class QwenDemo:
    def __init__(self, model_path="/remote-home1/share/models/Qwen2.5-0.5B-Instruct", 
                 adapter_path="./qwen_lora_output"):
        self.model_path = model_path
        self.adapter_path = adapter_path
        
        # åŠ è½½tokenizer
        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
        
        # åŠ è½½æ¨¡å‹
        self.base_model = AutoModelForCausalLM.from_pretrained(
            model_path,
            torch_dtype=torch.bfloat16,
            device_map="auto",
            trust_remote_code=True
        )
        
        # åŠ è½½LoRAé€‚é…å™¨
        try:
            self.model = PeftModel.from_pretrained(self.base_model, adapter_path)
            print("æˆåŠŸåŠ è½½LoRAé€‚é…å™¨")
        except Exception as e:
            print(f"æ— æ³•åŠ è½½LoRAé€‚é…å™¨: {e}")
            print("ä½¿ç”¨åŸå§‹æ¨¡å‹")
            self.model = self.base_model
        
        # åˆå§‹åŒ–æœç´¢å·¥å…·
        self.search_tool = FakeSearch()
        
        # æœç´¢å·¥å…·å®šä¹‰
        self.tool_definition = {
            "type": "function",
            "function": {
                "name": "search",
                "description": "æœç´¢å¼•æ“ï¼Œåœ¨éœ€è¦è·å–å®æ—¶ä¿¡æ¯ã€æœ€æ–°æ•°æ®ã€å…·ä½“äº‹å®æŸ¥è¯¢æ—¶éœ€è¦è°ƒç”¨æ­¤å·¥å…·",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "keyword": {"type": "string", "description": "ä½¿ç”¨æœç´¢å¼•æ“æ‰€éœ€çš„å…³é”®è¯"},
                        "top_k": {"type": "number", "default": 3, "description": "è¿”å›çš„æœç´¢ç»“æœæ•°é‡"}
                    },
                    "required": ["keyword"]
                }
            }
        }
        
        # å¯¹è¯å†å²
        self.conversation_history = []

    def extract_tool_call(self, response):
        """æå–å·¥å…·è°ƒç”¨"""
        # æŸ¥æ‰¾å·¥å…·è°ƒç”¨æ¨¡å¼
        tool_pattern = r'{"name":\s*"search",\s*"parameters":\s*{[^}]*}}'
        matches = re.findall(tool_pattern, response)
        
        if matches:
            try:
                tool_call = json.loads(matches[0])
                return tool_call
            except json.JSONDecodeError:
                pass
        
        # å°è¯•æ›´çµæ´»çš„åŒ¹é…
        if "search" in response and "keyword" in response:
            keyword_match = re.search(r'"keyword":\s*"([^"]+)"', response)
            if keyword_match:
                keyword = keyword_match.group(1)
                top_k_match = re.search(r'"top_k":\s*(\d+)', response)
                top_k = int(top_k_match.group(1)) if top_k_match else 3
                
                return {
                    "name": "search",
                    "parameters": {
                        "keyword": keyword,
                        "top_k": top_k
                    }
                }
        
        return None

    def call_tool(self, tool_call):
        """è°ƒç”¨å·¥å…·"""
        if tool_call["name"] == "search":
            params = tool_call["parameters"]
            keyword = params.get("keyword", "")
            top_k = params.get("top_k", 3)
            
            print(f"ğŸ” æœç´¢å…³é”®è¯: {keyword}")
            
            try:
                search_results = self.search_tool.search(keyword, top_k)
                return {
                    "name": "search",
                    "content": "\n".join([f"ç»“æœ{i+1}: {result}" for i, result in enumerate(search_results)])
                }
            except Exception as e:
                return {
                    "name": "search",
                    "content": f"æœç´¢å¤±è´¥: {str(e)}"
                }
        
        return None

    def generate_response(self, user_input, max_turns=3):
        """ç”Ÿæˆå›å¤ï¼Œæ”¯æŒå¤šè½®å·¥å…·è°ƒç”¨"""
        # æ„å»ºç³»ç»Ÿæç¤º
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨æœç´¢å·¥å…·è·å–ä¿¡æ¯ã€‚å½“éœ€è¦å®æ—¶ä¿¡æ¯ã€æœ€æ–°æ•°æ®æˆ–å…·ä½“äº‹å®æ—¶ï¼Œè¯·ä½¿ç”¨æœç´¢å·¥å…·ã€‚

å¯ç”¨å·¥å…·ï¼š
{json.dumps(self.tool_definition, ensure_ascii=False, indent=2)}

è¯·ä»”ç»†æ€è€ƒç”¨æˆ·çš„é—®é¢˜ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨æœç´¢å·¥å…·ã€‚å¦‚æœéœ€è¦ä½¿ç”¨å·¥å…·ï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è°ƒç”¨ï¼š
{{"name": "search", "parameters": {{"keyword": "æœç´¢å…³é”®è¯", "top_k": 3}}}}"""
        
        # æ„å»ºå¯¹è¯å†å²
        messages = [{"role": "system", "content": system_prompt}]
        messages.extend(self.conversation_history)
        messages.append({"role": "user", "content": user_input})
        
        for turn in range(max_turns):
            # ç”Ÿæˆå›å¤
            text = self.tokenizer.apply_chat_template(
                messages,
                tokenize=False,
                add_generation_prompt=True
            )
            
            inputs = self.tokenizer(text, return_tensors="pt").to(self.model.device)
            
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=1024,
                    do_sample=True,
                    temperature=0.7,
                    top_p=0.9,
                    pad_token_id=self.tokenizer.eos_token_id,
                    eos_token_id=self.tokenizer.eos_token_id
                )
            
            response = self.tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            tool_call = self.extract_tool_call(response)
            
            if tool_call:
                print(f"ğŸ¤– åŠ©æ‰‹æƒ³è¦è°ƒç”¨å·¥å…·: {tool_call['name']}")
                
                # è°ƒç”¨å·¥å…·
                tool_result = self.call_tool(tool_call)
                
                if tool_result:
                    # å°†å·¥å…·è°ƒç”¨å’Œç»“æœæ·»åŠ åˆ°å¯¹è¯å†å²
                    messages.append({"role": "assistant", "content": response})
                    messages.append({
                        "role": "tool",
                        "content": tool_result["content"],
                        "tool_call_id": tool_result["name"]
                    })
                    
                    # ç»§ç»­ç”ŸæˆåŸºäºå·¥å…·ç»“æœçš„å›å¤
                    continue
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¿”å›æœ€ç»ˆå›å¤
                return response.strip()
        
        # å¦‚æœè¾¾åˆ°æœ€å¤§è½®æ•°ï¼Œè¿”å›æœ€åçš„å›å¤
        return response.strip()

    def chat(self):
        """å¼€å§‹èŠå¤©"""
        print("=== QwenåŠ©æ‰‹ ===")
        print("è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
        print("è¾“å…¥ 'clear' æ¸…é™¤å¯¹è¯å†å²")
        print("=" * 50)
        
        while True:
            try:
                user_input = input("\nğŸ‘¤ ç”¨æˆ·: ").strip()
                
                if user_input.lower() in ['quit', 'exit']:
                    print("å†è§ï¼")
                    break
                
                if user_input.lower() == 'clear':
                    self.conversation_history = []
                    print("å¯¹è¯å†å²å·²æ¸…é™¤")
                    continue
                
                if not user_input:
                    continue
                
                # ç”Ÿæˆå›å¤
                print("\nğŸ¤– åŠ©æ‰‹: ", end="", flush=True)
                response = self.generate_response(user_input)
                print(response)
                
                # æ›´æ–°å¯¹è¯å†å²
                self.conversation_history.append({"role": "user", "content": user_input})
                self.conversation_history.append({"role": "assistant", "content": response})
                
                # é™åˆ¶å¯¹è¯å†å²é•¿åº¦
                if len(self.conversation_history) > 10:
                    self.conversation_history = self.conversation_history[-10:]
                
            except KeyboardInterrupt:
                print("\n\nå†è§ï¼")
                break
            except Exception as e:
                print(f"\nâŒ å‡ºç°é”™è¯¯: {e}")
                continue

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="Qwenäº¤äº’å¼æ¼”ç¤º")
    parser.add_argument("--model_path", type=str, default="/remote-home1/share/models/Qwen2.5-0.5B-Instruct")
    parser.add_argument("--adapter_path", type=str, default="./qwen_lora_output")
    
    args = parser.parse_args()
    
    # åˆ›å»ºæ¼”ç¤ºå®ä¾‹
    demo = QwenDemo(args.model_path, args.adapter_path)
    
    # å¼€å§‹èŠå¤©
    demo.chat()

if __name__ == "__main__":
    main()